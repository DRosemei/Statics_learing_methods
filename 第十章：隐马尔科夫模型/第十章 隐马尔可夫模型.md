# 第十章 隐马尔可夫模型

隐马尔可夫模型(hidden Markov model, HMM)是可**用于标注问题的统计学习模型**，描述**由隐藏的马尔可夫链随机生成观测序列**的过程，属于**生成模型**。



## 10.1 隐马尔科夫模型的基本概念

### 10.1.1 隐马尔科夫模型的定义

**定义10.1（隐马尔可夫模型）**隐马尔可夫模型是关于时序的概率模型，描述由一个**隐藏的马尔可夫链**随机生成不可观测的状态随机序列，再由各个状态生成一个观测从而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列，称为**状态序列**(state sequence)；每个状态生成一个观测，而由此产生的观测的随机序列，称为**观测序列**(observation sequence)。序列的每一个位置又可以看作是一个时刻。

**隐马尔可夫模型**由**初始概率分布**、**状态转移概率分布**以及**观测概率分布**确定。隐马尔可夫模型的形式定义如下：

![10.1.1（隐马尔科夫模型的定义）](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/10.1.1%EF%BC%88%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9A%E4%B9%89%EF%BC%89.PNG) 

隐马尔可夫模型做出了两个基本假设：

(1)**齐次马尔可夫性假设**，即假设隐藏的马尔可夫链在**任意时刻$t$状态只依于其前一时刻的状态**，与其他时刻的状态及观测无关，也与时刻$t$无关：
$$
P(i_t | i_{t-1}, o_{t-1}, ... , i_1, o_1) = P(i_t | i_{t-1}), \space t=1,2,...,T
$$
(2) **观测独立性假设**，即假设**任意时刻的观测只依赖于该时刻的马尔可夫链的状态**，与其他观测及状态无关。
$$
P(o_t | i_T, o_T, i_{T-1}, o_{T-1}, ... , i_{t+1}, o_{t+1}, i_{t}, i_{t-1}, o_{t-1}, ... , i_1, o_1) = P(o_t | i_t)
$$
隐马尔可夫模型可以用于标注，这时**状态**对应着**标记**。

标注问题是**给定观测的序列**预测**其对应的标记序列**。

### 10.1.2 观测序列的生成过程

![算法10.1（观测序列的生成）](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/%E7%AE%97%E6%B3%9510.1%EF%BC%88%E8%A7%82%E6%B5%8B%E5%BA%8F%E5%88%97%E7%9A%84%E7%94%9F%E6%88%90%EF%BC%89.PNG)

### 10.1.3 隐马尔可夫模型的三个基本问题

三个基本问题

1. **概率计算问题**。给定模型$\lambda = (A, B, \pi)$和观测序列$O=(o_1, o_2, ... ,o_T)$，计算在模型$\lambda$下观测序列$O$出现的**概率$P(O|\lambda)$**。
2. **学习问题**。已知观测序列$O=(o_1, o_2, ... ,o_T)$，**估计模型$\lambda = (A, B, \pi)$的参数**，使得在该模型问题下观测序列概率$P(O|\lambda)$最大。即用极大似然估计的方法估计参数。
3. 预测问题，也称解码问题。已知模型$\lambda = (A, B, \pi)$和观测序列$O=(o_1, o_2, ... ,o_T)$，求对给定观测序列条件概率$P(I|O)$最大的状态序列$I=(i_1,i_2,...,i_T)$。即**给定观测序列，求最有可能的对应的状态序列**。



## 10.2 概率计算算法

### 10.2.1 直接计算法

最直接的方法是按概率公式直接计算。通过列举所有可能的长度为$T$的状态序列$I=(i_1. i_2, ..., i_T)$，求各个状态序列$I$与观测序列$O=(o_1, o_2, ... ,o_T)$的**联合概率**$P(O,I|\lambda)$，然后对所有可能的状态序列求和，得到$P(O|\lambda)$。

计算量为$O(TN^T)$阶，不可行。

### 10.2.2 前向算法

![定义10.2（前向概率）](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/%E5%AE%9A%E4%B9%8910.2%EF%BC%88%E5%89%8D%E5%90%91%E6%A6%82%E7%8E%87%EF%BC%89.PNG)

![算法10.2（观测序列概率的前向算法）](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/%E7%AE%97%E6%B3%9510.2%EF%BC%88%E8%A7%82%E6%B5%8B%E5%BA%8F%E5%88%97%E6%A6%82%E7%8E%87%E7%9A%84%E5%89%8D%E5%90%91%E7%AE%97%E6%B3%95%EF%BC%89.PNG)

![图10.1前向概率的递推公式](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/%E5%9B%BE10.1%E5%89%8D%E5%90%91%E6%A6%82%E7%8E%87%E7%9A%84%E9%80%92%E6%8E%A8%E5%85%AC%E5%BC%8F.PNG)

减少计算量的原因在于**每一次计算直接引用前一个时刻的计算结果**，避免重复计算。利用前向概率计算$P(O|\lambda)$的计算量是$O(N^2T)$阶的。

![图10.2观测序列路径结构](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/%E5%9B%BE10.2%E8%A7%82%E6%B5%8B%E5%BA%8F%E5%88%97%E8%B7%AF%E5%BE%84%E7%BB%93%E6%9E%84.PNG)

### 10.2.3 后向算法

![定义10.3（后向概率）](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/%E5%AE%9A%E4%B9%8910.3%EF%BC%88%E5%90%8E%E5%90%91%E6%A6%82%E7%8E%87%EF%BC%89.PNG)

![算法10.3（观测序列概率的后向算法）](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/%E7%AE%97%E6%B3%9510.3%EF%BC%88%E8%A7%82%E6%B5%8B%E5%BA%8F%E5%88%97%E6%A6%82%E7%8E%87%E7%9A%84%E5%90%8E%E5%90%91%E7%AE%97%E6%B3%95%EF%BC%89.PNG)

![图10.3后向概率递推公式](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/%E5%9B%BE10.3%E5%90%8E%E5%90%91%E6%A6%82%E7%8E%87%E9%80%92%E6%8E%A8%E5%85%AC%E5%BC%8F.PNG)

利用前向概率和后向概率的定义可以将观测序列概率$P(O|\lambda)$统一写成
$$
P(O|\lambda)=\sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_t(i) \alpha_{ij} b_j(o_{t+1}) \beta_{t+1}(j), \space t=1,2,...,T-1
$$


### 10.2.4 一些概率与期望值的计算

1. 给定模型$\lambda$和观测$O$ ，在时刻$t$处于状态$q_i$的概率，记
   $$
   \gamma_t(i)=P(i_t=q_i|O,\lambda)
   $$
   又
   $$
   \gamma_t(i)=P(i_t=q_i|O,\lambda)=\frac{P(i_t=q_i,O|\lambda)}{P(O|\lambda)}  \\
   
   \alpha_t(i)\beta_t(i)=P(i_t=q_i,O|\lambda)
   $$
   得到
   $$
   \gamma_t(i)=\frac{\alpha_t(i)\beta_t(i)}{\sum_{j=1}^{N}\alpha_t(j)\beta_t(j)}
   $$
   
2. 给定模型$\lambda$和观测$O$ ，在时刻$t$处于状态$q_i$且在时刻$t+1$处于状态$q_j$的概率，记
   $$
   \xi_t(i,j)=P(i_t=q_i,i_{t+1}=q_j|O,\lambda)
   $$
   有
   $$
   \xi_t(i,j)=\frac{P(i_t=q_i,i_{t+1}=q_j,O|\lambda)}{P(O|\lambda)} \\
   =\frac{P(i_t=q_i,i_{t+1}=q_j,O|\lambda)}{\sum_{i=1}^{N}\sum_{j=1}^{N}P(i_t=q_i,i_{t+1}=q_j,O|\lambda)} \\
   =\frac{\alpha_t(i)\alpha_{ij}b_j(o_{t+1})\beta_{t+1}(j)}{\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha_t(i)\alpha_{ij}b_j(o_{t+1})\beta_{t+1}(j)}
   $$
   
3. 将$\gamma_t(i)$和$\xi_t(i,j)$对各个时刻$t$求和，可以得到

   1. 在观测$O$下状态$i$出现的期望值：
      $$
      \sum_{t=1}^{T}\gamma_t(i)
      $$
      
2. 在观测$O$下状态$i$转移的期望值：
      $$
      \sum_{t=1}^{T-1}\gamma_t(i)
      $$
      
   3. 在观测$O$下由状态$i$转移到状态$j$的期望值：
   $$
      \sum_{t=1}^{T-1}\xi_t(i,j)
      $$
      



## 10.3 学习算法

隐马尔可夫模型的学习，根据训练数据是包括**观测序列和对应的状态序列**还是**只有观测序列**，可以分别由监督学习与无监督学习实现。本节首先介绍监督学习算法，而后介绍无监督学习算法Baum-Welch 算法(也就是EM算法)。

### 10.3.1 监督学习方法

极大似然估计

![10.3.1HMM监督学习方法](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/10.3.1HMM%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95.PNG)

### 10.3.2 Baum-Welch算法

训练数据只包含$S$个长度为$T$的观测序列$\{O_1, O_2, ..., O_S\}$，目标是学习隐马尔可夫模型$\lambda=(A,B,\pi)$的参数。HMM事实上是一个含有隐变量的概率模型
$$
P(O|\lambda) = \underset{I}{\sum}P(O|I,\lambda)P(I|\lambda)
$$
推导详见p204-206

### 10.3.3 Baum-Welch模型参数估计公式

$$
\pi_i = \gamma_1(i)
$$

$$
a_{ij}=\frac{\sum_{t=1}^{T-1}\xi_t(i.j)}{\sum_{t=1}^{T-1}\gamma_t(i)}
$$


$$
b_j(k)=\frac{\sum_{t=1,o_t=v_k}^{T}\gamma_t(j)}{\sum_{t=1}^{T}\gamma_t(j)}
$$
![算法10.4（Baum-Welch算法）](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/%E7%AE%97%E6%B3%9510.4%EF%BC%88Baum-Welch%E7%AE%97%E6%B3%95%EF%BC%89.PNG)



## 10.4 预测算法

近似算法与维特比算法

### 10.4.1 近似算法

近似算法的想法是，在每个时刻$t$选择在该时刻最有可能出现的状态$i_t^*$，从而得到一个状态序列$I^*=(i_1^*, i_2^*, ..., i_T^*)$，将它作为预测的结果。

每一个时刻$t$最有可能的状态$i_t^*$是
$$
i_t^*=\arg \underset{1\leq i\leq N }{\max}[\gamma_t(i)], \space t=1,2,...,T
$$
近似算法的优点是计算简单，其缺点是不能保证预测的状态序列整体是最有可能的状态序列，因为预测的状态序列可能有实际不发生的部分。

### 10.4.2 维特比算法

用**动态规划**求概率最大路径(最优路径) 。这时一条路径对应着一个状态序列。

![10.4.2定义两个变量](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/10.4.2%E5%AE%9A%E4%B9%89%E4%B8%A4%E4%B8%AA%E5%8F%98%E9%87%8F.PNG)

**$\Psi_t(i)$表示当前时刻$t$，状态为$i$，$t-1$时刻概率最大的状态**。

![算法10.5（维特比算法）](https://raw.githubusercontent.com/DRosemei/statistical_learing_methods/master/imgs/%E7%AE%97%E6%B3%9510.5%EF%BC%88%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%EF%BC%89.PNG)

详见例10.3 p210-212

